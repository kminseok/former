[[142.   5.]
 [ 45. 101.]]
step4
{'acc': 0.8293515358361775, 'f1': 0.8015873015873016, 'precision': 0.9528301886792453, 'recall': 0.6917808219178082, 'test_loss': 0.41498740911483767}
saving model of step4
Model train epoch:1,loss:1.6196327805519104,training_time:1.5539498409998487
[[  0. 147.]
 [  0. 146.]]
step8
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.8802183389663696}
Model train epoch:2,loss:0.7529990673065186,training_time:0.7614320329994371
[[138.   9.]
 [ 29. 117.]]
step12
{'acc': 0.8703071672354948, 'f1': 0.8602941176470589, 'precision': 0.9285714285714286, 'recall': 0.8013698630136986, 'test_loss': 0.36884247660636904}
saving model of step12
Model train epoch:3,loss:0.7412044048309326,training_time:0.7331370879983297
[[  0. 147.]
 [  0. 146.]]
step16
{'acc': 0.49829351535836175, 'f1': 0.6651480637813212, 'precision': 0.49829351535836175, 'recall': 1.0, 'test_loss': 0.6075650334358216}
[[ 93.  54.]
 [ 10. 136.]]
step20
{'acc': 0.7815699658703071, 'f1': 0.8095238095238095, 'precision': 0.7157894736842105, 'recall': 0.9315068493150684, 'test_loss': 0.4793409049510956}
Model train epoch:4,loss:0.6817134737968444,training_time:0.8993834949978918
[[125.  22.]
 [ 18. 128.]]
step24
{'acc': 0.863481228668942, 'f1': 0.8648648648648649, 'precision': 0.8533333333333334, 'recall': 0.8767123287671232, 'test_loss': 0.37815041542053224}
Model train epoch:5,loss:0.5969519257545471,training_time:0.7094031199994788
[[ 99.  48.]
 [ 11. 135.]]
step28
{'acc': 0.7986348122866894, 'f1': 0.8206686930091185, 'precision': 0.7377049180327869, 'recall': 0.9246575342465754, 'test_loss': 0.4603385508060455}
Model train epoch:6,loss:0.5899747014045715,training_time:0.6876424900001439
[[ 88.  59.]
 [  8. 138.]]
step32
{'acc': 0.7713310580204779, 'f1': 0.8046647230320699, 'precision': 0.700507614213198, 'recall': 0.9452054794520548, 'test_loss': 0.5447844386100769}
Model train epoch:7,loss:0.5675606489181518,training_time:0.6929842800018378
[[114.  33.]
 [ 14. 132.]]
step36
{'acc': 0.8395904436860068, 'f1': 0.8488745980707395, 'precision': 0.8, 'recall': 0.9041095890410958, 'test_loss': 0.451425176858902}
[[103.  44.]
 [ 12. 134.]]
step40
{'acc': 0.8088737201365188, 'f1': 0.8271604938271605, 'precision': 0.7528089887640449, 'recall': 0.9178082191780822, 'test_loss': 0.48597057461738585}
Model train epoch:8,loss:0.5706928968429565,training_time:0.8526292060014384
[[ 82.  65.]
 [  5. 141.]]
step44
{'acc': 0.7610921501706485, 'f1': 0.8011363636363636, 'precision': 0.6844660194174758, 'recall': 0.9657534246575342, 'test_loss': 0.6390655219554902}
Model train epoch:9,loss:0.5809568047523499,training_time:0.7199882389977574
[[101.  46.]
 [ 12. 134.]]
step48
{'acc': 0.8020477815699659, 'f1': 0.8220858895705522, 'precision': 0.7444444444444445, 'recall': 0.9178082191780822, 'test_loss': 0.4957521200180054}
Model train epoch:10,loss:0.5850584387779236,training_time:0.7242281959988759
[[ 81.  66.]
 [  5. 141.]]
step52
{'acc': 0.757679180887372, 'f1': 0.7988668555240793, 'precision': 0.6811594202898551, 'recall': 0.9657534246575342, 'test_loss': 0.5976567149162293}
Model train epoch:11,loss:0.5718322038650513,training_time:0.6686176250004792
[[ 81.  66.]
 [  5. 141.]]
step56
{'acc': 0.757679180887372, 'f1': 0.7988668555240793, 'precision': 0.6811594202898551, 'recall': 0.9657534246575342, 'test_loss': 0.5846564769744873}
[[106.  41.]
 [ 12. 134.]]
step60
{'acc': 0.8191126279863481, 'f1': 0.8348909657320872, 'precision': 0.7657142857142857, 'recall': 0.9178082191780822, 'test_loss': 0.47660622000694275}
Model train epoch:12,loss:0.5425497651100158,training_time:0.8571145550013171
[[ 95.  52.]
 [  8. 138.]]
step64
{'acc': 0.7952218430034129, 'f1': 0.8214285714285714, 'precision': 0.7263157894736842, 'recall': 0.9452054794520548, 'test_loss': 0.5316538989543915}
Model train epoch:13,loss:0.531822395324707,training_time:0.6693911519978428
[[ 96.  51.]
 [  7. 139.]]
step68
{'acc': 0.8020477815699659, 'f1': 0.8273809523809523, 'precision': 0.7315789473684211, 'recall': 0.952054794520548, 'test_loss': 0.5389700353145599}
Model train epoch:14,loss:0.5668391108512878,training_time:0.6883224599987443
[[ 98.  49.]
 [  6. 140.]]
step72
{'acc': 0.8122866894197952, 'f1': 0.835820895522388, 'precision': 0.7407407407407407, 'recall': 0.958904109589041, 'test_loss': 0.5431215167045593}
Model train epoch:15,loss:0.5026382803916931,training_time:0.7007609030006279
[[ 99.  48.]
 [  7. 139.]]
step76
{'acc': 0.8122866894197952, 'f1': 0.8348348348348348, 'precision': 0.7433155080213903, 'recall': 0.952054794520548, 'test_loss': 0.5267666816711426}
[[108.  39.]
 [  8. 138.]]
step80
{'acc': 0.8395904436860068, 'f1': 0.8544891640866873, 'precision': 0.7796610169491526, 'recall': 0.9452054794520548, 'test_loss': 0.4722566187381744}
Model train epoch:16,loss:0.48793073296546935,training_time:0.8706163409988221
[[118.  29.]
 [ 11. 135.]]
step84
{'acc': 0.863481228668942, 'f1': 0.8709677419354839, 'precision': 0.823170731707317, 'recall': 0.9246575342465754, 'test_loss': 0.4015062749385834}
Model train epoch:17,loss:0.46435468792915346,training_time:0.7210180750007567
[[105.  42.]
 [  6. 140.]]
step88
{'acc': 0.8361774744027304, 'f1': 0.8536585365853658, 'precision': 0.7692307692307693, 'recall': 0.958904109589041, 'test_loss': 0.45764055848121643}
Model train epoch:18,loss:0.40620180368423464,training_time:0.7100087899998471
[[121.  26.]
 [ 10. 136.]]
step92
{'acc': 0.8771331058020477, 'f1': 0.8831168831168831, 'precision': 0.8395061728395061, 'recall': 0.9315068493150684, 'test_loss': 0.36516464948654176}
saving model of step92
Model train epoch:19,loss:0.5170491516590119,training_time:0.7314173819977441
[[121.  26.]
 [  8. 138.]]
step96
{'acc': 0.8839590443686007, 'f1': 0.8903225806451613, 'precision': 0.8414634146341463, 'recall': 0.9452054794520548, 'test_loss': 0.38060425519943236}
saving model of step96
[[113.  34.]
 [  7. 139.]]
step100
{'acc': 0.8600682593856656, 'f1': 0.8714733542319749, 'precision': 0.8034682080924855, 'recall': 0.952054794520548, 'test_loss': 0.4043764352798462}
Model train epoch:20,loss:0.4359312117099762,training_time:0.8698010160005651
[[ 95.  52.]
 [  6. 140.]]
step104
{'acc': 0.8020477815699659, 'f1': 0.8284023668639053, 'precision': 0.7291666666666666, 'recall': 0.958904109589041, 'test_loss': 0.4781923472881317}
Model train epoch:21,loss:0.3667811453342438,training_time:0.7027635459999146
[[ 69.  78.]
 [  7. 139.]]
step108
{'acc': 0.7098976109215017, 'f1': 0.7658402203856749, 'precision': 0.6405529953917051, 'recall': 0.952054794520548, 'test_loss': 0.90019850730896}
Model train epoch:22,loss:0.43899351358413696,training_time:0.6866501990007237
[[119.  28.]
 [ 10. 136.]]
step112
{'acc': 0.8703071672354948, 'f1': 0.8774193548387097, 'precision': 0.8292682926829268, 'recall': 0.9315068493150684, 'test_loss': 0.40498493909835814}
Model train epoch:23,loss:0.2831138789653778,training_time:0.7149549380010285
[[128.  19.]
 [ 14. 132.]]
step116
{'acc': 0.8873720136518771, 'f1': 0.8888888888888888, 'precision': 0.8741721854304636, 'recall': 0.9041095890410958, 'test_loss': 0.3467283397912979}
saving model of step116
[[130.  17.]
 [ 15. 131.]]
step120
{'acc': 0.8907849829351536, 'f1': 0.891156462585034, 'precision': 0.8851351351351351, 'recall': 0.8972602739726028, 'test_loss': 0.35408317744731904}
saving model of step120
Model train epoch:24,loss:0.23148362338542938,training_time:0.8917593660007697
[[ 88.  59.]
 [ 11. 135.]]
step124
{'acc': 0.7610921501706485, 'f1': 0.7941176470588235, 'precision': 0.6958762886597938, 'recall': 0.9246575342465754, 'test_loss': 0.8871799230575561}
Model train epoch:25,loss:0.2871340185403824,training_time:0.7139440970022406
[[111.  36.]
 [ 16. 130.]]
step128
{'acc': 0.8225255972696246, 'f1': 0.8333333333333334, 'precision': 0.7831325301204819, 'recall': 0.8904109589041096, 'test_loss': 0.6296291589736939}
Model train epoch:26,loss:0.16339655220508575,training_time:0.7266249749991402
[[127.  20.]
 [ 18. 128.]]
step132
{'acc': 0.8703071672354948, 'f1': 0.8707482993197279, 'precision': 0.8648648648648649, 'recall': 0.8767123287671232, 'test_loss': 0.4870614230632782}
Model train epoch:27,loss:0.14943661391735077,training_time:0.6968818899986218
[[ 99.  48.]
 [ 21. 125.]]
step136
{'acc': 0.764505119453925, 'f1': 0.7836990595611285, 'precision': 0.7225433526011561, 'recall': 0.8561643835616438, 'test_loss': 1.0503767132759094}
[[118.  29.]
 [ 22. 124.]]
step140
{'acc': 0.825938566552901, 'f1': 0.8294314381270903, 'precision': 0.8104575163398693, 'recall': 0.8493150684931506, 'test_loss': 0.8399893283843994}
Model train epoch:28,loss:0.07631051810458303,training_time:0.8387610970021342
[[129.  18.]
 [ 22. 124.]]
step144
{'acc': 0.863481228668942, 'f1': 0.8611111111111112, 'precision': 0.8732394366197183, 'recall': 0.8493150684931506, 'test_loss': 0.7744928956031799}
Model train epoch:29,loss:0.05004273287486285,training_time:0.7253837319985905
[[112.  35.]
 [ 20. 126.]]
step148
{'acc': 0.8122866894197952, 'f1': 0.8208469055374593, 'precision': 0.782608695652174, 'recall': 0.863013698630137, 'test_loss': 1.0644076347351075}
Model train epoch:30,loss:0.09270492494106293,training_time:0.7206606520012429
[[118.  29.]
 [ 20. 126.]]
step152
{'acc': 0.8327645051194539, 'f1': 0.8372093023255814, 'precision': 0.8129032258064516, 'recall': 0.863013698630137, 'test_loss': 0.9152986526489257}
Model train epoch:31,loss:0.039846830256283286,training_time:0.6900597489984648
[[121.  26.]
 [ 21. 125.]]
step156
{'acc': 0.8395904436860068, 'f1': 0.8417508417508418, 'precision': 0.8278145695364238, 'recall': 0.8561643835616438, 'test_loss': 0.8452043294906616}
[[112.  35.]
 [ 17. 129.]]
step160
{'acc': 0.8225255972696246, 'f1': 0.832258064516129, 'precision': 0.7865853658536586, 'recall': 0.8835616438356164, 'test_loss': 0.8153407275676727}
Model train epoch:32,loss:0.07515455596148968,training_time:0.8496546300011687
[[118.  29.]
 [ 20. 126.]]
step164
{'acc': 0.8327645051194539, 'f1': 0.8372093023255814, 'precision': 0.8129032258064516, 'recall': 0.863013698630137, 'test_loss': 0.785849106311798}
Model train epoch:33,loss:0.019016942474991083,training_time:0.7030153970008541
[[108.  39.]
 [ 22. 124.]]
step168
{'acc': 0.7918088737201365, 'f1': 0.8025889967637541, 'precision': 0.7607361963190185, 'recall': 0.8493150684931506, 'test_loss': 1.0709805607795715}
Model train epoch:34,loss:0.009643194125965237,training_time:0.6895452719982131
[[117.  30.]
 [ 25. 121.]]
step172
{'acc': 0.8122866894197952, 'f1': 0.8148148148148148, 'precision': 0.8013245033112583, 'recall': 0.8287671232876712, 'test_loss': 1.0844947695732117}
Model train epoch:35,loss:0.12614078185288236,training_time:0.692305500000657
[[118.  29.]
 [ 27. 119.]]
step176
{'acc': 0.8088737201365188, 'f1': 0.8095238095238095, 'precision': 0.8040540540540541, 'recall': 0.815068493150685, 'test_loss': 1.2206916570663453}
[[ 97.  50.]
 [ 31. 115.]]
step180
{'acc': 0.7235494880546075, 'f1': 0.7395498392282959, 'precision': 0.696969696969697, 'recall': 0.7876712328767124, 'test_loss': 1.6274983644485475}
Model train epoch:36,loss:0.06056268849351909,training_time:0.8933226750014001
[[132.  15.]
 [ 24. 122.]]
step184
{'acc': 0.8668941979522184, 'f1': 0.8621908127208481, 'precision': 0.8905109489051095, 'recall': 0.8356164383561644, 'test_loss': 0.8235548377037049}
Model train epoch:37,loss:0.034504900500178334,training_time:0.6882143069997255
[[ 98.  49.]
 [ 21. 125.]]
step188
{'acc': 0.7610921501706485, 'f1': 0.78125, 'precision': 0.7183908045977011, 'recall': 0.8561643835616438, 'test_loss': 1.3159716129302979}
Model train epoch:38,loss:0.05965011618973222,training_time:0.6903371439984767
[[113.  34.]
 [ 24. 122.]]
step192
{'acc': 0.8020477815699659, 'f1': 0.8079470198675497, 'precision': 0.782051282051282, 'recall': 0.8356164383561644, 'test_loss': 0.8179236650466919}
Model train epoch:39,loss:0.06304684206843376,training_time:0.6979357310010528
[[120.  27.]
 [ 24. 122.]]
step196
{'acc': 0.825938566552901, 'f1': 0.8271186440677966, 'precision': 0.8187919463087249, 'recall': 0.8356164383561644, 'test_loss': 0.7222018420696259}
[[122.  25.]
 [ 23. 123.]]
step200
{'acc': 0.8361774744027304, 'f1': 0.8367346938775511, 'precision': 0.831081081081081, 'recall': 0.8424657534246576, 'test_loss': 0.7664187729358674}
Model train epoch:40,loss:0.013810774311423302,training_time:0.8360361160011962
[[115.  32.]
 [ 20. 126.]]
step204
{'acc': 0.8225255972696246, 'f1': 0.8289473684210527, 'precision': 0.7974683544303798, 'recall': 0.863013698630137, 'test_loss': 0.9477590799331665}
Model train epoch:41,loss:0.0034760174225084484,training_time:0.6678451070001756
[[112.  35.]
 [ 19. 127.]]
step208
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0508302330970765}
Model train epoch:42,loss:0.00233092587441206,training_time:0.6664842179998232
[[105.  42.]
 [ 22. 124.]]
step212
{'acc': 0.7815699658703071, 'f1': 0.7948717948717948, 'precision': 0.7469879518072289, 'recall': 0.8493150684931506, 'test_loss': 1.2854462146759034}
Model train epoch:43,loss:0.01782322027720511,training_time:0.6730215589996078
[[119.  28.]
 [ 24. 122.]]
step216
{'acc': 0.8225255972696246, 'f1': 0.8243243243243243, 'precision': 0.8133333333333334, 'recall': 0.8356164383561644, 'test_loss': 1.0349627017974854}
[[127.  20.]
 [ 25. 121.]]
step220
{'acc': 0.8464163822525598, 'f1': 0.8432055749128919, 'precision': 0.8581560283687943, 'recall': 0.8287671232876712, 'test_loss': 0.8417573809623718}
Model train epoch:44,loss:0.023314122395822777,training_time:0.8351097830018261
[[119.  28.]
 [ 22. 124.]]
step224
{'acc': 0.8293515358361775, 'f1': 0.8322147651006712, 'precision': 0.8157894736842105, 'recall': 0.8493150684931506, 'test_loss': 0.8100442290306091}
Model train epoch:45,loss:0.02418897610041313,training_time:0.6801597350022348
[[113.  34.]
 [ 25. 121.]]
step228
{'acc': 0.7986348122866894, 'f1': 0.8039867109634552, 'precision': 0.7806451612903226, 'recall': 0.8287671232876712, 'test_loss': 0.9403271794319152}
Model train epoch:46,loss:0.010109648259822279,training_time:0.699959988000046
[[117.  30.]
 [ 29. 117.]]
step232
{'acc': 0.7986348122866894, 'f1': 0.7986348122866894, 'precision': 0.7959183673469388, 'recall': 0.8013698630136986, 'test_loss': 0.9789207816123963}
Model train epoch:47,loss:0.004525191010907292,training_time:0.7388933250003902
[[127.  20.]
 [ 32. 114.]]
step236
{'acc': 0.8225255972696246, 'f1': 0.8142857142857143, 'precision': 0.8507462686567164, 'recall': 0.7808219178082192, 'test_loss': 0.930750721693039}
[[101.  46.]
 [ 29. 117.]]
step240
{'acc': 0.7440273037542662, 'f1': 0.7572815533980582, 'precision': 0.7177914110429447, 'recall': 0.8013698630136986, 'test_loss': 1.4574754118919373}
Model train epoch:48,loss:0.0031007130077341572,training_time:0.8363735359998827
[[131.  16.]
 [ 32. 114.]]
step244
{'acc': 0.8361774744027304, 'f1': 0.8260869565217391, 'precision': 0.8769230769230769, 'recall': 0.7808219178082192, 'test_loss': 0.8863251030445098}
Model train epoch:49,loss:0.009682677543605678,training_time:0.7756800629977079
[[ 98.  49.]
 [ 20. 126.]]
step248
{'acc': 0.764505119453925, 'f1': 0.7850467289719626, 'precision': 0.72, 'recall': 0.863013698630137, 'test_loss': 1.5094645500183106}
Model train epoch:50,loss:0.05317287895304616,training_time:0.6906811940025364
[[102.  45.]
 [ 18. 128.]]
step252
{'acc': 0.7849829351535836, 'f1': 0.8025078369905956, 'precision': 0.7398843930635838, 'recall': 0.8767123287671232, 'test_loss': 1.074517285823822}
Model train epoch:51,loss:0.002038900216575712,training_time:0.7191920559998835
[[110.  37.]
 [ 21. 125.]]
step256
{'acc': 0.8020477815699659, 'f1': 0.8116883116883117, 'precision': 0.7716049382716049, 'recall': 0.8561643835616438, 'test_loss': 0.9273791551589966}
[[104.  43.]
 [ 22. 124.]]
step260
{'acc': 0.7781569965870307, 'f1': 0.792332268370607, 'precision': 0.7425149700598802, 'recall': 0.8493150684931506, 'test_loss': 0.994205629825592}
Model train epoch:52,loss:0.0029042428301181643,training_time:0.8529253470005642
[[115.  32.]
 [ 21. 125.]]
step264
{'acc': 0.8191126279863481, 'f1': 0.8250825082508251, 'precision': 0.7961783439490446, 'recall': 0.8561643835616438, 'test_loss': 0.8743405401706695}
Model train epoch:53,loss:0.0029864256270229817,training_time:0.6816898539982503
[[120.  27.]
 [ 19. 127.]]
step268
{'acc': 0.8430034129692833, 'f1': 0.8466666666666667, 'precision': 0.8246753246753247, 'recall': 0.8698630136986302, 'test_loss': 0.7860139727592468}
Model train epoch:54,loss:0.0007885878905653954,training_time:0.6788364479980373
[[120.  27.]
 [ 21. 125.]]
step272
{'acc': 0.8361774744027304, 'f1': 0.8389261744966443, 'precision': 0.8223684210526315, 'recall': 0.8561643835616438, 'test_loss': 0.8158504605293274}
Model train epoch:55,loss:0.0008768000770942308,training_time:0.7300852059997851
[[116.  31.]
 [ 21. 125.]]
step276
{'acc': 0.8225255972696246, 'f1': 0.8278145695364238, 'precision': 0.8012820512820513, 'recall': 0.8561643835616438, 'test_loss': 0.8769804775714874}
[[112.  35.]
 [ 19. 127.]]
step280
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 0.9392382621765136}
Model train epoch:56,loss:0.00029823307850165295,training_time:0.8194118440005695
[[111.  36.]
 [ 19. 127.]]
step284
{'acc': 0.8122866894197952, 'f1': 0.8220064724919094, 'precision': 0.7791411042944786, 'recall': 0.8698630136986302, 'test_loss': 0.9759457826614379}
Model train epoch:57,loss:0.00014309645775938406,training_time:0.6783412469994801
[[112.  35.]
 [ 19. 127.]]
step288
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 0.9977049946784973}
Model train epoch:58,loss:0.00017064317653421314,training_time:0.6728534559988475
[[112.  35.]
 [ 18. 128.]]
step292
{'acc': 0.8191126279863481, 'f1': 0.8284789644012945, 'precision': 0.7852760736196319, 'recall': 0.8767123287671232, 'test_loss': 1.002669596672058}
Model train epoch:59,loss:6.562508278875611e-05,training_time:0.6783987290000368
[[113.  34.]
 [ 19. 127.]]
step296
{'acc': 0.8191126279863481, 'f1': 0.8273615635179153, 'precision': 0.7888198757763976, 'recall': 0.8698630136986302, 'test_loss': 1.0006390929222106}
[[112.  35.]
 [ 19. 127.]]
step300
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0059534311294556}
Model train epoch:60,loss:6.881578010506929e-05,training_time:0.8158995380035776
[[112.  35.]
 [ 19. 127.]]
step304
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0095099687576294}
Model train epoch:61,loss:4.648298126994632e-05,training_time:0.7133902259993192
[[112.  35.]
 [ 19. 127.]]
step308
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0082811951637267}
Model train epoch:62,loss:3.587737464840757e-05,training_time:0.6876093259998015
[[112.  35.]
 [ 19. 127.]]
step312
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0073645472526551}
Model train epoch:63,loss:3.207365843991283e-05,training_time:0.6766322969997418
[[112.  35.]
 [ 19. 127.]]
step316
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0083052039146423}
[[112.  35.]
 [ 19. 127.]]
step320
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0109590649604798}
Model train epoch:64,loss:3.080455535382498e-05,training_time:0.8475456279993523
[[112.  35.]
 [ 19. 127.]]
step324
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.013996171951294}
Model train epoch:65,loss:3.400828318262938e-05,training_time:0.6831382569980633
[[112.  35.]
 [ 19. 127.]]
step328
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.016958510875702}
Model train epoch:66,loss:2.467985141265672e-05,training_time:0.668327932999091
[[112.  35.]
 [ 19. 127.]]
step332
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0189679622650147}
Model train epoch:67,loss:2.4882911748136394e-05,training_time:0.700895011999819
[[112.  35.]
 [ 19. 127.]]
step336
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0207928657531737}
[[112.  35.]
 [ 19. 127.]]
step340
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0228880763053894}
Model train epoch:68,loss:2.7533910542842933e-05,training_time:0.8813024360024428
[[112.  35.]
 [ 19. 127.]]
step344
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0254287719726562}
Model train epoch:69,loss:2.2141780209494755e-05,training_time:0.7314489410018723
[[112.  35.]
 [ 19. 127.]]
step348
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0269716024398803}
Model train epoch:70,loss:2.0990621123928577e-05,training_time:0.7073652239996591
[[112.  35.]
 [ 19. 127.]]
step352
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0277442574501037}
Model train epoch:71,loss:2.4594710703240706e-05,training_time:0.714868294999178
[[112.  35.]
 [ 19. 127.]]
step356
{'acc': 0.8156996587030717, 'f1': 0.8246753246753247, 'precision': 0.7839506172839507, 'recall': 0.8698630136986302, 'test_loss': 1.0282241463661195}
[[113.  34.]
 [ 19. 127.]]
step360
{'acc': 0.8191126279863481, 'f1': 0.8273615635179153, 'precision': 0.7888198757763976, 'recall': 0.8698630136986302, 'test_loss': 1.0287167429924011}
Model train epoch:72,loss:2.1221282440819778e-05,training_time:0.8884242240019375
[[113.  34.]
 [ 19. 127.]]
step364
{'acc': 0.8191126279863481, 'f1': 0.8273615635179153, 'precision': 0.7888198757763976, 'recall': 0.8698630136986302, 'test_loss': 1.0292678117752074}
Model train epoch:73,loss:2.0817138647544198e-05,training_time:0.6988237799996568
[[113.  34.]
 [ 19. 127.]]
step368
{'acc': 0.8191126279863481, 'f1': 0.8273615635179153, 'precision': 0.7888198757763976, 'recall': 0.8698630136986302, 'test_loss': 1.0303515434265136}
Model train epoch:74,loss:1.9857567895087414e-05,training_time:0.6979426199977752
[[114.  33.]
 [ 19. 127.]]
step372
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0313964009284973}
Model train epoch:75,loss:2.081880084006116e-05,training_time:0.6855707699978666
[[114.  33.]
 [ 19. 127.]]
step376
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0329620718955994}
[[114.  33.]
 [ 19. 127.]]
step380
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0347256302833556}
Model train epoch:76,loss:1.8380127039563375e-05,training_time:0.8324075480013562
[[114.  33.]
 [ 19. 127.]]
step384
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0365400433540344}
Model train epoch:77,loss:1.7312774252786768e-05,training_time:0.6934781669988297
[[114.  33.]
 [ 19. 127.]]
step388
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0373324632644654}
Model train epoch:78,loss:1.7916275101015345e-05,training_time:0.7028239110004506
[[114.  33.]
 [ 19. 127.]]
step392
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0381286501884461}
Model train epoch:79,loss:1.9383064864086918e-05,training_time:0.6770748050003021
[[114.  33.]
 [ 19. 127.]]
step396
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.039635920524597}
[[114.  33.]
 [ 19. 127.]]
step400
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0410476326942444}
Model train epoch:80,loss:1.743670400173869e-05,training_time:0.8262189000015496
[[114.  33.]
 [ 19. 127.]]
step404
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0421779990196227}
Model train epoch:81,loss:1.6568919090786948e-05,training_time:0.6611120169982314
[[114.  33.]
 [ 19. 127.]]
step408
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0430387139320374}
Model train epoch:82,loss:1.7213452883879655e-05,training_time:0.6901553550014796
[[114.  33.]
 [ 19. 127.]]
step412
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0435127377510072}
Model train epoch:83,loss:1.6141879314091057e-05,training_time:0.6681552929985628
[[114.  33.]
 [ 19. 127.]]
step416
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0435603737831116}
[[114.  33.]
 [ 19. 127.]]
step420
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0432474970817567}
Model train epoch:84,loss:1.4946986448194366e-05,training_time:0.8490115239983425
[[114.  33.]
 [ 19. 127.]]
step424
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.042553687095642}
Model train epoch:85,loss:1.5265235197148287e-05,training_time:0.7294040560009307
[[114.  33.]
 [ 19. 127.]]
step428
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0420434832572938}
Model train epoch:86,loss:1.4777207252336665e-05,training_time:0.708089324998582
[[114.  33.]
 [ 19. 127.]]
step432
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0416614234447479}
Model train epoch:87,loss:1.3597217184724287e-05,training_time:0.6989051150012529
[[114.  33.]
 [ 19. 127.]]
step436
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0414379715919495}
[[114.  33.]
 [ 19. 127.]]
step440
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.04192773103714}
Model train epoch:88,loss:1.3555885561800097e-05,training_time:0.8815632149999146
[[114.  33.]
 [ 19. 127.]]
step444
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.043821358680725}
Model train epoch:89,loss:1.3004046013520566e-05,training_time:0.7113416959982715
[[114.  33.]
 [ 19. 127.]]
step448
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.045047515630722}
Model train epoch:90,loss:1.3925285566074308e-05,training_time:0.6696392449994164
[[114.  33.]
 [ 19. 127.]]
step452
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0463204205036163}
Model train epoch:91,loss:1.4335652303998359e-05,training_time:0.7058028530009324
[[114.  33.]
 [ 19. 127.]]
step456
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0474207401275635}
[[114.  33.]
 [ 19. 127.]]
step460
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0484301269054412}
Model train epoch:92,loss:1.3795287850371097e-05,training_time:0.8321699670013913
[[114.  33.]
 [ 19. 127.]]
step464
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0494057178497314}
Model train epoch:93,loss:1.3325924919627142e-05,training_time:0.6997953649988631
[[114.  33.]
 [ 19. 127.]]
step468
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0502246081829072}
Model train epoch:94,loss:1.210766067742952e-05,training_time:0.6785448340015137
[[114.  33.]
 [ 19. 127.]]
step472
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.050942724943161}
Model train epoch:95,loss:1.2773350135830697e-05,training_time:0.6901636239999789
[[114.  33.]
 [ 19. 127.]]
step476
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0518151104450226}
[[114.  33.]
 [ 19. 127.]]
step480
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0526731967926026}
Model train epoch:96,loss:1.2641853754757903e-05,training_time:0.8262164109983132
[[114.  33.]
 [ 19. 127.]]
step484
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.053762936592102}
Model train epoch:97,loss:1.3184110684960615e-05,training_time:0.7037828730026376
[[114.  33.]
 [ 19. 127.]]
step488
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0544831097126006}
Model train epoch:98,loss:1.218254601553781e-05,training_time:0.7090571819971956
[[114.  33.]
 [ 19. 127.]]
step492
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.054949587583542}
Model train epoch:99,loss:1.2514079026004766e-05,training_time:0.7133966559995315
[[114.  33.]
 [ 19. 127.]]
step496
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0556437194347381}
[[114.  33.]
 [ 19. 127.]]
step500
{'acc': 0.8225255972696246, 'f1': 0.8300653594771242, 'precision': 0.79375, 'recall': 0.8698630136986302, 'test_loss': 1.0560058891773223}
Model train epoch:100,loss:1.1737251952581573e-05,training_time:0.8493307700009609
